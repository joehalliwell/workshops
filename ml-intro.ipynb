{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to data science and machine learning with Python\n",
    "We're going to run through a series of steps and challenges. If you get stuck at any point please feel free to ask one of our volunteers for help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Anaconda\n",
    "\n",
    "Go to https://www.continuum.io/downloads/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the workshop notebook\n",
    "\n",
    "Download https://github.com/joehalliwell/ml-workshop/raw/master/ml-intro.ipynb \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Jupyter Notebook\n",
    "\n",
    "Jupyter is a tool for interacting with code and data in a variety of languages. Today (obviously) we're using it with Python 3, but you can find out more about what it can do at http://jupyter.org/\n",
    "\n",
    "Just from Start > All Programs > Anaconda > Jupyter (or similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Jupyter basics\n",
    "\n",
    "When you started Jupyter a new browser tab should have opened. Load the \"ml-intro.ipynb\" file you just downloaded. \n",
    "\n",
    "### Challenges\n",
    "\n",
    "1. Go to the \"Help\" menu above and run through the \"User Interface Tour\"\n",
    "2. Click into the \"In\" box below and hit `control + enter` to execute it. What happens?\n",
    "3. Click the \"+\" button to create a new code block. Type in `1337 + 1337` and hit `control + enter` to evaluate.\n",
    "4. Click the scissors button to remove it\n",
    "5. Pop-up documentation by click on the function name `format` in the grey block below and pressing `shift + tab`. You can use the controls in the top-right of the pop-up to see more info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getuser\n",
    "print(\"{0} RULEZ!!!\".format(getuser()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Python basics\n",
    "\n",
    "Practice a bit of Python. Skip this if you're totally on top of the Python thing.\n",
    "\n",
    "### Challenges\n",
    "\n",
    "1. Print the result of *multiplying* `1337` by `1337` (*Hint*: you can print a number with `print(123)`)\n",
    "2. Create a list called `adjectives` containing *five* adjectives (*Hint*: you can define a list of words with `words = [\"hello\", \"world\"]`)\n",
    "3. Print the length of `adjectives`(*Hint*: use the built-in `len(...)` function to get the length of a list)\n",
    "3. Import the `choice` function from the `random` standard library; use it to print a random adjective (*Hint*: use `from MODULE import FUNCTION` to import a function)\n",
    "4. Create a list of nounds called `nouns`\n",
    "5. Define a function `make_codename()` to return a random combination of adjective and noun (*Hint*: see below for a sample function definition)\n",
    "6. (**Tricky!**) Generate five *distinct* codenames (*Hint*: you can use `set([1,1,3])` to maintain a set of distinct items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function definition\n",
    "\n",
    "def make_countdown():\n",
    "    result = \"\"\n",
    "    for n in (\"Five\", \"Four\", \"Three\", \"Two\", \"One\"):\n",
    "        result += n + \"...\\n\" # \\n is the \"new line\" character\n",
    "    result += \"Blastoff!\\n\"\n",
    "    return result\n",
    "    \n",
    "print(make_countdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pandas\n",
    "\n",
    "Pandas is a widely-used library for working with tables of data called \"dataframes\". You can find out more at http://pandas.pydata.org/\n",
    "\n",
    "We're going to work with a dataset about passengers on the ill-fated Titanic. This is an introductory machine learning challenge on https://www.kaggle.com/c/titanic.\n",
    "\n",
    "You can read more about this dataset (including field descriptions) at https://www.kaggle.com/c/titanic/data.\n",
    "\n",
    "### Challenges\n",
    "\n",
    "1. Run the snippet below to read in the \"Titanic\" dataset from the interwebs. Do you understand what each line is doing?\n",
    "2. Run `titanic.head()` to look at the first few rows of the dataframe\n",
    "3. Experiment with the `sample()`, `info()` and `describe()` methods. Remember that you can use `shift + tab` to access documentation!\n",
    "4. Why are the counts in the `info()` output different for different fields?\n",
    "4. The average age in the dataset can be found via `titanic['Age'].mean()`, but what is the sum of eveyone's ages?\n",
    "4. You can filter the dataset to just women via `titanic[titanic['Sex'] == 'female']`. What's the average age of women in the dataset?\n",
    "5. (**Tricky!**) What's the average age of female survivors?\n",
    "5. What is `titanic.groupby(['Sex', 'Survived']).describe()` showing you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Show more than the default numer of data rows\n",
    "pd.set_option('max_rows', 50)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/joehalliwell/ml-workshop/master/train.csv\"\n",
    "titanic = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Matplotlib and Seaborn\n",
    "\n",
    "There are a lot of different Python libraries for visualising data. **Matplotlib** is one of the most powerful and widely used. In fact, as we'll see it's integrated with pandas! We're just going to be doing some basic charting, but you can see more of its capabilities at https://matplotlib.org/gallery.html.\n",
    "\n",
    "**Seaborn** gives matplotlib a nicer default style and provides some utility functions. You can read more about using it with pandas here: http://seaborn.pydata.org/tutorial/categorical.html\n",
    "\n",
    "### Challenges\n",
    "\n",
    "1. Run the snippets below to do some basic charting\n",
    "2. Take a look at the pandas visualisation guide https://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
    "3. Experiment! Make something cool and show everyone :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Pandas has built in methods for simple visualisations\n",
    "titanic[\"Sex\"].value_counts().plot(kind=\"bar\", title=\"Sex of passengers\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival rate analysis by ticket class\n",
    "ax = titanic.groupby(\"Pclass\")[\"Survived\"].mean().plot(kind=\"bar\", label=\"Survival Rate\")\n",
    "ax.set_xlabel('Ticket class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn offers concise ways to construct complex charts\n",
    "sns.barplot(x=\"Embarked\", y=\"Survived\", hue=\"Sex\", data=titanic)\n",
    "sns.pairplot(x_vars=[\"Age\"], y_vars=[\"Fare\"], data=titanic, hue=\"Embarked\", size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis: see https://en.wikipedia.org/wiki/Correlogram\n",
    "# What is this telling us about the relationship between Pclass and Fare?\n",
    "\n",
    "correlations = titanic[['Survived', 'Pclass', 'Fare' , 'Age']].corr()\n",
    "print(correlations)\n",
    "sns.heatmap(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different segments via a facet grid\n",
    "grid = sns.FacetGrid(titanic, col='Survived', row='Pclass', size=2.2, aspect=1)\n",
    "grid.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# You can also use matplotlib directly\n",
    "plt.hist(titanic['Fare'], label=\"Fare\")\n",
    "\n",
    "X = np.linspace(0, 600)\n",
    "for d in np.linspace(100, 600, 10):\n",
    "    plt.plot(X, d + 50 * np.sin(X / 50), linestyle='dotted', linewidth=10)\n",
    "    \n",
    "plt.title(\"Histogram of fares plus squiggles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Scikit Learn\n",
    "\n",
    "Scikit Learn (http://scikit-learn.org) is a brilliant library that contains a bunch of textbook machine learning algorithms, plus machinery for running and evaluating experiments. We're going to use it to build a simple model called a decision tree.\n",
    "\n",
    "### Cleaning up the data: plugging missing values\n",
    "\n",
    "In data science and machine learning it is common to spend a lot of time cleaning up and pre-processing data. The Titanic dataset is no expection.\n",
    "\n",
    "First there are a few values missing from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, metrics, preprocessing, model_selection\n",
    "\n",
    "# Let's work on a copy of the data\n",
    "train = titanic.copy()\n",
    "\n",
    "# Here's the problem...\n",
    "problems = train.isnull().any(axis=1)\n",
    "print(train[problems].head())\n",
    "print(\"Problem rows: {0}\".format(train.isnull().any(axis=1).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to plug some missing values. See https://pandas.pydata.org/pandas-docs/stable/missing_data.html for other ideas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_data(df):\n",
    "    \"\"\"Fill in missing values in a few key fields\"\"\"\n",
    "    \n",
    "    # Replace missing ports of embarkation with 'U'\n",
    "    df['Embarked'] = df['Embarked'].fillna('U') # For unknown\n",
    "\n",
    "    # Replace missing ages with the median age\n",
    "    medianAge = df['Age'].dropna().median()\n",
    "    df['Age'] = df['Age'].fillna(medianAge)\n",
    "\n",
    "    # Replace missing cabins with 'U' and strip back to deck letter\n",
    "    df['Cabin'] = df['Cabin'].fillna('U')\n",
    "    df['Cabin'] = df['Cabin'].map(lambda cabin: cabin[0])\n",
    "\n",
    "    medianFare = df['Fare'].dropna().median()\n",
    "    df['Fare'] = df['Fare'].fillna(medianFare)\n",
    "    \n",
    "# Check that it's fixed\n",
    "fill_missing_data(train)\n",
    "print(train[problems].head())\n",
    "print(\"Problem rows: {0}\".format(train.isnull().any(axis=1).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing the data: encoding nominal data\n",
    "\n",
    "Now we're going to convert the \"categorical\" or \"nominal\" data into numbers. \n",
    "\n",
    "Decision trees are actually capable of working with non-numerical data, but unfortunately the Scikit Learn implementation isn't yet!\n",
    "\n",
    "For our classifier it's okay to just replace each category with a code number. We can do this automatically with Scikit Learn's LabelEncoder. But there are other possibilities that you can read about at http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = {col: preprocessing.LabelEncoder() for col in \"Cabin Embarked Sex\".split()}\n",
    "\n",
    "def encode(df):\n",
    "    \"\"\"Encode a few categorical columns\"\"\"\n",
    "    for col, encoder in encoders.items():\n",
    "         df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "encode(train)\n",
    "\n",
    "# Show the trained encoders\n",
    "for col, enc in encoders.items():\n",
    "    print(col, {c:enc.transform([c])[0] for c in enc.classes_})\n",
    "\n",
    "train.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \"Pclass Sex Age Fare Cabin Embarked\".split()\n",
    "\n",
    "X = train[cols]\n",
    "y = train[\"Survived\"]\n",
    "          \n",
    "model = tree.DecisionTreeClassifier(max_depth=3)\n",
    "model.fit(X, y)\n",
    "print(\"Accuracy on training data:\", model.score(X, y))\n",
    "print(metrics.classification_report(model.predict(X), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the coolest things about decision trees is that it's easy to visualise them and understand their behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz # conda install -c conda-forge python-graphviz\n",
    "\n",
    "dot = tree.export_graphviz(model, out_file=None, \n",
    "                         feature_names=X.columns,  \n",
    "                         class_names=['Died', 'Survived'],  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "\n",
    "graphviz.Source(dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree classifier has an argument `max_depth` which limits the size of the tree. This is known as a hyper-parameter to distinguish it from the regular parameters that a machine learning algorithm will try to optimize.\n",
    "\n",
    "So what happens if we increase the `max_depth` of the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(max_depth=10)\n",
    "model.fit(X, y)\n",
    "print(\"Accuracy on training data:\", model.score(X, y))\n",
    "print(metrics.classification_report(model.predict(X), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the accuracy of the model on the training data has improved, it may not be a better model.\n",
    "\n",
    "The only way to know for sure is to train the model on one set of data and then test it on an *previously unseen* set of data.\n",
    "\n",
    "A standard way to do this is via *cross-validation*: you split the data into N chunks, train on (N-1) chunks and test on the final one. You do this for each chunk and take an average.\n",
    "\n",
    "This is what the `model_selection.cross_val_score(...)` function does. \n",
    "\n",
    "In the snippet below we're going to look at how increasing the maximum depth of the tree impacts on the training accuracy and (more importantly) cross-validation scores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_scores = []\n",
    "x_scores = []\n",
    "for depth in range(1,50):\n",
    "    model = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    model.fit(X, y)\n",
    "    t_scores.append((depth, model.score(X, y)))\n",
    "    x_scores.append((depth, model_selection.cross_val_score(model, X, y).mean()))\n",
    "\n",
    "plt.plot(*zip(*t_scores))\n",
    "plt.title(\"Training accuracy\")\n",
    "plt.show()\n",
    "plt.plot(*zip(*x_scores))\n",
    "plt.title(\"Cross-validation accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best value for `max_depth` is 5.\n",
    "\n",
    "Finally, we can run a trained model on unseen (or \"held out\") data. You can use this to submit to https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tree.DecisionTreeClassifier(max_depth=5)\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Generate the test set\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/joehalliwell/ml-workshop/master/test.csv\")\n",
    "fill_missing_data(test)\n",
    "encode(test)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(best_model.predict(test[cols]), columns=(\"Survived\",))\n",
    "\n",
    "submission = pd.concat((test['PassengerId'], predictions), axis=1)\n",
    "submission.to_csv(\"submission.csv\", index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Over to you!\n",
    "\n",
    "- Would a different classifier work better? There are tons to try! http://scikit-learn.org/stable/supervised_learning.html\n",
    "- Join Kaggle and submit your predictions!\n",
    "- Would a one-hot encoding be better? http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "- Try visualising the decision surface: http://scikit-learn.org/stable/auto_examples/tree/plot_iris.html#sphx-glr-auto-examples-tree-plot-iris-py \n",
    "\n",
    "## 10. References\n",
    "\n",
    "- Intro to pandas: http://synesthesiam.com/posts/an-introduction-to-pandas.html\n",
    "- Cheatsheets: https://startupsventurecapital.com/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5 \n",
    "- Titanic tutorials: https://www.kaggle.com/c/titanic#tutorials\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}